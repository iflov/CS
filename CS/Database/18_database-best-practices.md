---
tags:
  - database
  - best-practices
  - design-patterns
  - optimization
  - maintenance
  - monitoring
  - architecture
created: 2025-01-08
updated: 2025-01-08
---

# ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë²” ì‚¬ë¡€ (Database Best Practices)

> [!info] ê°œìš”
> ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„, ê°œë°œ, ìš´ì˜ì—ì„œ ê²€ì¦ëœ ëª¨ë²” ì‚¬ë¡€ë“¤ì„ ì¢…í•©ì ìœ¼ë¡œ ë‹¤ë£¹ë‹ˆë‹¤. ì´ëŸ¬í•œ ì›ì¹™ë“¤ì„ ë”°ë¥´ë©´ í™•ì¥ ê°€ëŠ¥í•˜ê³ , ìœ ì§€ë³´ìˆ˜ê°€ ì‰¬ìš°ë©°, ì„±ëŠ¥ì´ ë›°ì–´ë‚œ ë°ì´í„°ë² ì´ìŠ¤ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“‘ ëª©ì°¨

- [[#âš¡ ë¹ ë¥¸ ì‹œì‘]]
- [[#ğŸ”§ ì„¤ê³„ ëª¨ë²” ì‚¬ë¡€]]
- [[#ğŸ’¡ ê°œë°œ ëª¨ë²” ì‚¬ë¡€]]
- [[#ğŸš€ ìš´ì˜ ëª¨ë²” ì‚¬ë¡€]]
- [[#âš ï¸ ì£¼ì˜ì‚¬í•­]]
- [[#ğŸ“š ì°¸ê³ ìë£Œ]]

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### í•µì‹¬ ì›ì¹™ ì²´í¬ë¦¬ìŠ¤íŠ¸

> [!tip] 10ê°€ì§€ í•µì‹¬ ì›ì¹™
> - [ ] **ì •ê·œí™”ì™€ ì—­ì •ê·œí™” ê· í˜•**: 3NFë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ë˜ ì„±ëŠ¥ì„ ìœ„í•´ ì„ íƒì  ì—­ì •ê·œí™”
> - [ ] **ì¸ë±ìŠ¤ ì „ëµ**: ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„ í›„ ìµœì í™”ëœ ì¸ë±ìŠ¤ ì„¤ê³„
> - [ ] **ëª…ëª… ê·œì¹™ ì¼ê´€ì„±**: í…Œì´ë¸”, ì»¬ëŸ¼, ì¸ë±ìŠ¤ ëª…ëª… ê·œì¹™ í‘œì¤€í™”
> - [ ] **íŠ¸ëœì­ì…˜ ê´€ë¦¬**: ACID ì›ì¹™ ì¤€ìˆ˜ì™€ ì ì ˆí•œ ê²©ë¦¬ ìˆ˜ì¤€ ì„¤ì •
> - [ ] **ë°±ì—… ì „ëµ**: ì •ê¸°ì ì¸ ë°±ì—…ê³¼ ë³µêµ¬ í…ŒìŠ¤íŠ¸
> - [ ] **ëª¨ë‹ˆí„°ë§**: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
> - [ ] **ë³´ì•ˆ**: ìµœì†Œ ê¶Œí•œ ì›ì¹™ê³¼ ë°ì´í„° ì•”í˜¸í™”
> - [ ] **ë¬¸ì„œí™”**: ìŠ¤í‚¤ë§ˆ, API, ìš´ì˜ ì ˆì°¨ ë¬¸ì„œí™”
> - [ ] **ë²„ì „ ê´€ë¦¬**: ìŠ¤í‚¤ë§ˆ ë³€ê²½ ì´ë ¥ ê´€ë¦¬
> - [ ] **í…ŒìŠ¤íŠ¸**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ì™€ í†µí•© í…ŒìŠ¤íŠ¸ êµ¬í˜„

### TypeScript ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ í”„ë ˆì„ì›Œí¬

```typescript
import mysql from 'mysql2/promise';
import { z } from 'zod';

// 1. ì—°ê²° í’€ ê´€ë¦¬
class DatabaseConnectionPool {
  private static instance: DatabaseConnectionPool;
  private pool: mysql.Pool;

  private constructor(config: mysql.PoolOptions) {
    this.pool = mysql.createPool({
      ...config,
      waitForConnections: true,
      connectionLimit: 10,
      maxIdle: 10,
      idleTimeout: 60000,
      queueLimit: 0,
      enableKeepAlive: true,
      keepAliveInitialDelay: 0
    });
  }

  static getInstance(config?: mysql.PoolOptions): DatabaseConnectionPool {
    if (!DatabaseConnectionPool.instance) {
      if (!config) throw new Error('Config required for first initialization');
      DatabaseConnectionPool.instance = new DatabaseConnectionPool(config);
    }
    return DatabaseConnectionPool.instance;
  }

  async getConnection(): Promise<mysql.PoolConnection> {
    return await this.pool.getConnection();
  }

  async execute<T>(
    query: string,
    params?: any[]
  ): Promise<T[]> {
    const [rows] = await this.pool.execute(query, params);
    return rows as T[];
  }

  async transaction<T>(
    callback: (connection: mysql.PoolConnection) => Promise<T>
  ): Promise<T> {
    const connection = await this.getConnection();
    
    try {
      await connection.beginTransaction();
      const result = await callback(connection);
      await connection.commit();
      return result;
    } catch (error) {
      await connection.rollback();
      throw error;
    } finally {
      connection.release();
    }
  }

  async close(): Promise<void> {
    await this.pool.end();
  }
}

// 2. ìŠ¤í‚¤ë§ˆ ê²€ì¦
const UserSchema = z.object({
  id: z.number().positive(),
  username: z.string().min(3).max(50),
  email: z.string().email(),
  created_at: z.date(),
  updated_at: z.date()
});

type User = z.infer<typeof UserSchema>;

// 3. Repository íŒ¨í„´
abstract class BaseRepository<T> {
  constructor(
    protected db: DatabaseConnectionPool,
    protected tableName: string,
    protected schema: z.ZodSchema<T>
  ) {}

  async findById(id: number): Promise<T | null> {
    const rows = await this.db.execute<T>(
      `SELECT * FROM ${this.tableName} WHERE id = ?`,
      [id]
    );
    
    if (rows.length === 0) return null;
    
    return this.schema.parse(rows[0]);
  }

  async findAll(
    limit: number = 100,
    offset: number = 0
  ): Promise<T[]> {
    const rows = await this.db.execute<T>(
      `SELECT * FROM ${this.tableName} LIMIT ? OFFSET ?`,
      [limit, offset]
    );
    
    return rows.map(row => this.schema.parse(row));
  }

  async create(data: Partial<T>): Promise<number> {
    const validated = this.schema.partial().parse(data);
    const columns = Object.keys(validated);
    const values = Object.values(validated);
    const placeholders = columns.map(() => '?').join(', ');
    
    const [result] = await this.db.execute<any>(
      `INSERT INTO ${this.tableName} (${columns.join(', ')})
       VALUES (${placeholders})`,
      values
    );
    
    return result.insertId;
  }

  async update(id: number, data: Partial<T>): Promise<boolean> {
    const validated = this.schema.partial().parse(data);
    const updates = Object.keys(validated)
      .map(key => `${key} = ?`)
      .join(', ');
    const values = [...Object.values(validated), id];
    
    const [result] = await this.db.execute<any>(
      `UPDATE ${this.tableName} SET ${updates} WHERE id = ?`,
      values
    );
    
    return result.affectedRows > 0;
  }

  async delete(id: number): Promise<boolean> {
    const [result] = await this.db.execute<any>(
      `DELETE FROM ${this.tableName} WHERE id = ?`,
      [id]
    );
    
    return result.affectedRows > 0;
  }
}

// 4. ì¿¼ë¦¬ ë¹Œë”
class QueryBuilder<T> {
  private selectClause: string[] = ['*'];
  private whereConditions: string[] = [];
  private joinClauses: string[] = [];
  private orderByClause?: string;
  private limitValue?: number;
  private offsetValue?: number;
  private params: any[] = [];

  constructor(private tableName: string) {}

  select(...columns: string[]): this {
    this.selectClause = columns;
    return this;
  }

  where(condition: string, value?: any): this {
    this.whereConditions.push(condition);
    if (value !== undefined) {
      this.params.push(value);
    }
    return this;
  }

  join(
    type: 'INNER' | 'LEFT' | 'RIGHT',
    table: string,
    on: string
  ): this {
    this.joinClauses.push(`${type} JOIN ${table} ON ${on}`);
    return this;
  }

  orderBy(column: string, direction: 'ASC' | 'DESC' = 'ASC'): this {
    this.orderByClause = `${column} ${direction}`;
    return this;
  }

  limit(value: number): this {
    this.limitValue = value;
    return this;
  }

  offset(value: number): this {
    this.offsetValue = value;
    return this;
  }

  build(): { query: string; params: any[] } {
    let query = `SELECT ${this.selectClause.join(', ')} FROM ${this.tableName}`;
    
    if (this.joinClauses.length > 0) {
      query += ` ${this.joinClauses.join(' ')}`;
    }
    
    if (this.whereConditions.length > 0) {
      query += ` WHERE ${this.whereConditions.join(' AND ')}`;
    }
    
    if (this.orderByClause) {
      query += ` ORDER BY ${this.orderByClause}`;
    }
    
    if (this.limitValue !== undefined) {
      query += ` LIMIT ${this.limitValue}`;
    }
    
    if (this.offsetValue !== undefined) {
      query += ` OFFSET ${this.offsetValue}`;
    }
    
    return { query, params: this.params };
  }
}
```

---

## ğŸ”§ ì„¤ê³„ ëª¨ë²” ì‚¬ë¡€

### 1. ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ì›ì¹™

> [!note] ì„¤ê³„ ì§€ì¹¨
> - **ì ì ˆí•œ ë°ì´í„° íƒ€ì… ì„ íƒ**: ì €ì¥ ê³µê°„ê³¼ ì„±ëŠ¥ ìµœì í™”
> - **ì œì•½ì¡°ê±´ í™œìš©**: CHECK, UNIQUE, NOT NULL ì ê·¹ í™œìš©
> - **ê´€ê³„ ëª…í™•í™”**: ì™¸ë˜ í‚¤ë¡œ ì°¸ì¡° ë¬´ê²°ì„± ë³´ì¥
> - **ì‹œê°„ ë°ì´í„° í‘œì¤€í™”**: UTC ì‚¬ìš©, íƒ€ì„ì¡´ ë³„ë„ ì €ì¥

```typescript
// ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ê´€ë¦¬
class SchemaMigrationManager {
  private migrations: Map<number, Migration> = new Map();

  constructor(private db: DatabaseConnectionPool) {}

  // ë§ˆì´ê·¸ë ˆì´ì…˜ í…Œì´ë¸” ìƒì„±
  async initialize(): Promise<void> {
    await this.db.execute(`
      CREATE TABLE IF NOT EXISTS schema_migrations (
        version INT PRIMARY KEY,
        name VARCHAR(255) NOT NULL,
        executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        execution_time_ms INT,
        checksum VARCHAR(64)
      )
    `);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ë“±ë¡
  register(migration: Migration): void {
    this.migrations.set(migration.version, migration);
  }

  // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
  async migrate(): Promise<void> {
    const executed = await this.getExecutedMigrations();
    const pending = Array.from(this.migrations.entries())
      .filter(([version]) => !executed.includes(version))
      .sort(([a], [b]) => a - b);

    for (const [version, migration] of pending) {
      await this.executeMigration(version, migration);
    }
  }

  private async executeMigration(
    version: number,
    migration: Migration
  ): Promise<void> {
    const startTime = Date.now();
    
    await this.db.transaction(async (connection) => {
      // ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
      await migration.up(connection);
      
      // ê¸°ë¡
      const executionTime = Date.now() - startTime;
      const checksum = this.calculateChecksum(migration.sql);
      
      await connection.execute(
        `INSERT INTO schema_migrations (version, name, execution_time_ms, checksum)
         VALUES (?, ?, ?, ?)`,
        [version, migration.name, executionTime, checksum]
      );
    });

    console.log(`âœ… Migration ${version}: ${migration.name} completed`);
  }

  private async getExecutedMigrations(): Promise<number[]> {
    const rows = await this.db.execute<{ version: number }>(
      'SELECT version FROM schema_migrations'
    );
    
    return rows.map(row => row.version);
  }

  private calculateChecksum(sql: string): string {
    const crypto = require('crypto');
    return crypto.createHash('sha256').update(sql).digest('hex');
  }

  // ë¡¤ë°± ê¸°ëŠ¥
  async rollback(targetVersion?: number): Promise<void> {
    const executed = await this.getExecutedMigrations();
    const toRollback = targetVersion 
      ? executed.filter(v => v > targetVersion)
      : [Math.max(...executed)];

    for (const version of toRollback.sort((a, b) => b - a)) {
      const migration = this.migrations.get(version);
      if (!migration) {
        throw new Error(`Migration ${version} not found`);
      }

      await this.db.transaction(async (connection) => {
        await migration.down(connection);
        await connection.execute(
          'DELETE FROM schema_migrations WHERE version = ?',
          [version]
        );
      });

      console.log(`â†©ï¸ Rolled back migration ${version}: ${migration.name}`);
    }
  }
}

interface Migration {
  version: number;
  name: string;
  sql: string;
  up: (connection: mysql.PoolConnection) => Promise<void>;
  down: (connection: mysql.PoolConnection) => Promise<void>;
}

// ë§ˆì´ê·¸ë ˆì´ì…˜ ì˜ˆì œ
const migration001: Migration = {
  version: 1,
  name: 'create_users_table',
  sql: `
    CREATE TABLE users (
      id INT AUTO_INCREMENT PRIMARY KEY,
      username VARCHAR(50) UNIQUE NOT NULL,
      email VARCHAR(255) UNIQUE NOT NULL,
      password_hash VARCHAR(255) NOT NULL,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
      INDEX idx_username (username),
      INDEX idx_email (email),
      INDEX idx_created_at (created_at)
    )
  `,
  up: async (connection) => {
    await connection.execute(migration001.sql);
  },
  down: async (connection) => {
    await connection.execute('DROP TABLE IF EXISTS users');
  }
};
```

### 2. ì¸ë±ìŠ¤ ì„¤ê³„ ì „ëµ

```typescript
// ì¸ë±ìŠ¤ ë¶„ì„ ë° ì¶”ì²œ ì‹œìŠ¤í…œ
class IndexAdvisor {
  constructor(private db: DatabaseConnectionPool) {}

  // ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¶„ì„
  async analyzeSlowQueries(
    threshold: number = 1000 // ms
  ): Promise<Array<{
    query: string;
    executionTime: number;
    recommendations: string[];
  }>> {
    const slowQueries = await this.db.execute<any>(`
      SELECT 
        query,
        execution_time_ms,
        rows_examined,
        rows_sent
      FROM performance_schema.events_statements_history_long
      WHERE execution_time_ms > ?
      ORDER BY execution_time_ms DESC
      LIMIT 100
    `, [threshold]);

    const recommendations = [];
    
    for (const query of slowQueries) {
      const explain = await this.explainQuery(query.query);
      const suggestion = this.generateIndexRecommendation(explain);
      
      recommendations.push({
        query: query.query,
        executionTime: query.execution_time_ms,
        recommendations: suggestion
      });
    }

    return recommendations;
  }

  // ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„
  private async explainQuery(query: string): Promise<any[]> {
    try {
      return await this.db.execute(`EXPLAIN ${query}`);
    } catch (error) {
      console.error('Failed to explain query:', error);
      return [];
    }
  }

  // ì¸ë±ìŠ¤ ì¶”ì²œ ìƒì„±
  private generateIndexRecommendation(explain: any[]): string[] {
    const recommendations: string[] = [];

    for (const row of explain) {
      // í’€ í…Œì´ë¸” ìŠ¤ìº” ê°ì§€
      if (row.type === 'ALL') {
        recommendations.push(
          `Consider adding index on ${row.table} for WHERE clause columns`
        );
      }

      // íŒŒì¼ ì •ë ¬ ê°ì§€
      if (row.Extra && row.Extra.includes('Using filesort')) {
        recommendations.push(
          `Consider adding index for ORDER BY columns on ${row.table}`
        );
      }

      // ì„ì‹œ í…Œì´ë¸” ì‚¬ìš© ê°ì§€
      if (row.Extra && row.Extra.includes('Using temporary')) {
        recommendations.push(
          `Consider optimizing GROUP BY or DISTINCT on ${row.table}`
        );
      }

      // ì¸ë±ìŠ¤ ë¯¸ì‚¬ìš© ê°ì§€
      if (!row.key) {
        recommendations.push(
          `No index used for ${row.table}. Consider adding appropriate index`
        );
      }
    }

    return recommendations;
  }

  // ì¤‘ë³µ ì¸ë±ìŠ¤ ì°¾ê¸°
  async findDuplicateIndexes(): Promise<Map<string, string[]>> {
    const indexes = await this.db.execute<any>(`
      SELECT 
        TABLE_NAME,
        INDEX_NAME,
        GROUP_CONCAT(COLUMN_NAME ORDER BY SEQ_IN_INDEX) as columns
      FROM information_schema.STATISTICS
      WHERE TABLE_SCHEMA = DATABASE()
      GROUP BY TABLE_NAME, INDEX_NAME
    `);

    const duplicates = new Map<string, string[]>();

    // ë™ì¼í•œ ì»¬ëŸ¼ ì¡°í•©ì„ ê°€ì§„ ì¸ë±ìŠ¤ ì°¾ê¸°
    const indexMap = new Map<string, string[]>();
    
    for (const index of indexes) {
      const key = `${index.TABLE_NAME}:${index.columns}`;
      
      if (indexMap.has(key)) {
        const existing = indexMap.get(key)!;
        duplicates.set(index.TABLE_NAME, [
          ...existing,
          index.INDEX_NAME
        ]);
      } else {
        indexMap.set(key, [index.INDEX_NAME]);
      }
    }

    return duplicates;
  }

  // ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ ì°¾ê¸°
  async findUnusedIndexes(days: number = 30): Promise<any[]> {
    return await this.db.execute(`
      SELECT 
        object_schema,
        object_name,
        index_name
      FROM performance_schema.table_io_waits_summary_by_index_usage
      WHERE index_name IS NOT NULL
        AND count_star = 0
        AND object_schema = DATABASE()
    `);
  }
}
```

---

## ğŸ’¡ ê°œë°œ ëª¨ë²” ì‚¬ë¡€

### 1. ì¿¼ë¦¬ ìµœì í™”

```typescript
// ì¿¼ë¦¬ ìµœì í™” ìœ í‹¸ë¦¬í‹°
class QueryOptimizer {
  constructor(private db: DatabaseConnectionPool) {}

  // N+1 ë¬¸ì œ í•´ê²°
  async fetchUsersWithPosts(): Promise<any[]> {
    // âŒ Bad: N+1 ì¿¼ë¦¬
    // const users = await db.execute('SELECT * FROM users');
    // for (const user of users) {
    //   user.posts = await db.execute(
    //     'SELECT * FROM posts WHERE user_id = ?',
    //     [user.id]
    //   );
    // }

    // âœ… Good: JOIN ì‚¬ìš©
    const result = await this.db.execute(`
      SELECT 
        u.id as user_id,
        u.username,
        u.email,
        p.id as post_id,
        p.title,
        p.content,
        p.created_at as post_created_at
      FROM users u
      LEFT JOIN posts p ON u.id = p.user_id
      ORDER BY u.id, p.created_at DESC
    `);

    // ê²°ê³¼ ì¬êµ¬ì„±
    const usersMap = new Map<number, any>();
    
    for (const row of result) {
      if (!usersMap.has(row.user_id)) {
        usersMap.set(row.user_id, {
          id: row.user_id,
          username: row.username,
          email: row.email,
          posts: []
        });
      }

      if (row.post_id) {
        usersMap.get(row.user_id)!.posts.push({
          id: row.post_id,
          title: row.title,
          content: row.content,
          created_at: row.post_created_at
        });
      }
    }

    return Array.from(usersMap.values());
  }

  // í˜ì´ì§• ìµœì í™”
  async optimizedPagination(
    page: number,
    pageSize: number,
    lastId?: number
  ): Promise<any[]> {
    // âŒ Bad: OFFSET ì‚¬ìš© (ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ ëŠë¦¼)
    // return await db.execute(
    //   'SELECT * FROM posts ORDER BY id LIMIT ? OFFSET ?',
    //   [pageSize, (page - 1) * pageSize]
    // );

    // âœ… Good: Keyset pagination
    if (lastId) {
      return await this.db.execute(
        `SELECT * FROM posts 
         WHERE id > ? 
         ORDER BY id 
         LIMIT ?`,
        [lastId, pageSize]
      );
    } else {
      return await this.db.execute(
        'SELECT * FROM posts ORDER BY id LIMIT ?',
        [pageSize]
      );
    }
  }

  // ë°°ì¹˜ ì‘ì—… ìµœì í™”
  async batchInsert<T>(
    tableName: string,
    data: T[],
    batchSize: number = 1000
  ): Promise<void> {
    if (data.length === 0) return;

    const columns = Object.keys(data[0]);
    const columnString = columns.join(', ');

    for (let i = 0; i < data.length; i += batchSize) {
      const batch = data.slice(i, i + batchSize);
      
      const placeholders = batch
        .map(() => `(${columns.map(() => '?').join(', ')})`)
        .join(', ');
      
      const values = batch.flatMap(row => 
        columns.map(col => (row as any)[col])
      );

      await this.db.execute(
        `INSERT INTO ${tableName} (${columnString}) VALUES ${placeholders}`,
        values
      );
    }
  }

  // ì¿¼ë¦¬ ìºì‹±
  private queryCache = new Map<string, { data: any; timestamp: number }>();
  private cacheTTL = 60000; // 1ë¶„

  async cachedQuery<T>(
    key: string,
    query: string,
    params: any[] = [],
    ttl: number = this.cacheTTL
  ): Promise<T[]> {
    const cached = this.queryCache.get(key);
    
    if (cached && Date.now() - cached.timestamp < ttl) {
      return cached.data;
    }

    const result = await this.db.execute<T>(query, params);
    
    this.queryCache.set(key, {
      data: result,
      timestamp: Date.now()
    });

    // ìºì‹œ í¬ê¸° ì œí•œ
    if (this.queryCache.size > 100) {
      const oldestKey = Array.from(this.queryCache.entries())
        .sort(([, a], [, b]) => a.timestamp - b.timestamp)[0][0];
      this.queryCache.delete(oldestKey);
    }

    return result;
  }
}
```

### 2. ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„

```typescript
// ê°•ê±´í•œ ì—ëŸ¬ ì²˜ë¦¬
class ResilientDatabase {
  private retryConfig = {
    maxRetries: 3,
    initialDelay: 100,
    maxDelay: 5000,
    backoffMultiplier: 2
  };

  constructor(private db: DatabaseConnectionPool) {}

  // ì¬ì‹œë„ ë¡œì§
  async executeWithRetry<T>(
    operation: () => Promise<T>,
    context: string
  ): Promise<T> {
    let lastError: Error | null = null;
    let delay = this.retryConfig.initialDelay;

    for (let attempt = 1; attempt <= this.retryConfig.maxRetries; attempt++) {
      try {
        return await operation();
      } catch (error: any) {
        lastError = error;

        // ì¬ì‹œë„ ê°€ëŠ¥í•œ ì—ëŸ¬ì¸ì§€ í™•ì¸
        if (!this.isRetryableError(error)) {
          throw error;
        }

        if (attempt < this.retryConfig.maxRetries) {
          console.log(
            `Retry ${attempt}/${this.retryConfig.maxRetries} for ${context} after ${delay}ms`
          );
          
          await this.sleep(delay);
          delay = Math.min(
            delay * this.retryConfig.backoffMultiplier,
            this.retryConfig.maxDelay
          );
        }
      }
    }

    throw new Error(
      `Operation failed after ${this.retryConfig.maxRetries} retries: ${lastError?.message}`
    );
  }

  private isRetryableError(error: any): boolean {
    const retryableCodes = [
      'ETIMEDOUT',
      'ECONNREFUSED',
      'ECONNRESET',
      'ER_LOCK_DEADLOCK',
      'ER_LOCK_WAIT_TIMEOUT'
    ];

    return retryableCodes.includes(error.code);
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´
  private circuitState: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';
  private failureCount = 0;
  private successCount = 0;
  private lastFailureTime?: number;
  private readonly failureThreshold = 5;
  private readonly successThreshold = 3;
  private readonly timeout = 60000; // 1ë¶„

  async executeWithCircuitBreaker<T>(
    operation: () => Promise<T>
  ): Promise<T> {
    // ì„œí‚·ì´ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸
    if (this.circuitState === 'OPEN') {
      if (Date.now() - (this.lastFailureTime || 0) > this.timeout) {
        this.circuitState = 'HALF_OPEN';
        this.successCount = 0;
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    try {
      const result = await operation();

      // ì„±ê³µ ì²˜ë¦¬
      if (this.circuitState === 'HALF_OPEN') {
        this.successCount++;
        if (this.successCount >= this.successThreshold) {
          this.circuitState = 'CLOSED';
          this.failureCount = 0;
        }
      } else {
        this.failureCount = 0;
      }

      return result;
    } catch (error) {
      // ì‹¤íŒ¨ ì²˜ë¦¬
      this.failureCount++;
      this.lastFailureTime = Date.now();

      if (this.failureCount >= this.failureThreshold) {
        this.circuitState = 'OPEN';
      }

      throw error;
    }
  }
}
```

---

## ğŸš€ ìš´ì˜ ëª¨ë²” ì‚¬ë¡€

### 1. ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

```typescript
// ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
class DatabaseMonitor {
  private metrics: Map<string, any[]> = new Map();
  private alerts: Array<{
    condition: (metrics: any) => boolean;
    message: string;
    severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';
  }> = [];

  constructor(private db: DatabaseConnectionPool) {
    this.setupDefaultAlerts();
  }

  // ê¸°ë³¸ ì•Œë¦¼ ì„¤ì •
  private setupDefaultAlerts(): void {
    // ì—°ê²° í’€ ì‚¬ìš©ë¥ 
    this.addAlert(
      metrics => metrics.connectionPoolUsage > 90,
      'Connection pool usage above 90%',
      'HIGH'
    );

    // ìŠ¬ë¡œìš° ì¿¼ë¦¬
    this.addAlert(
      metrics => metrics.slowQueryCount > 10,
      'High number of slow queries detected',
      'MEDIUM'
    );

    // ë””ìŠ¤í¬ ì‚¬ìš©ë¥ 
    this.addAlert(
      metrics => metrics.diskUsage > 85,
      'Disk usage above 85%',
      'HIGH'
    );

    // ë³µì œ ì§€ì—°
    this.addAlert(
      metrics => metrics.replicationLag > 5000,
      'Replication lag exceeds 5 seconds',
      'CRITICAL'
    );
  }

  // ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  async collectMetrics(): Promise<Record<string, any>> {
    const metrics: Record<string, any> = {};

    // ì—°ê²° ì •ë³´
    const [connections] = await this.db.execute<any>(`
      SHOW STATUS WHERE Variable_name IN (
        'Threads_connected',
        'Max_used_connections',
        'Aborted_connects'
      )
    `);

    connections.forEach((conn: any) => {
      metrics[conn.Variable_name] = parseInt(conn.Value);
    });

    // ì¿¼ë¦¬ ì„±ëŠ¥
    const [queryStats] = await this.db.execute<any>(`
      SHOW STATUS WHERE Variable_name IN (
        'Slow_queries',
        'Questions',
        'Com_select',
        'Com_insert',
        'Com_update',
        'Com_delete'
      )
    `);

    queryStats.forEach((stat: any) => {
      metrics[stat.Variable_name] = parseInt(stat.Value);
    });

    // InnoDB ë©”íŠ¸ë¦­
    const [innodbStats] = await this.db.execute<any>(`
      SHOW STATUS WHERE Variable_name LIKE 'Innodb_%'
    `);

    innodbStats.forEach((stat: any) => {
      metrics[stat.Variable_name] = stat.Value;
    });

    // í…Œì´ë¸” í¬ê¸°
    const [tableSize] = await this.db.execute<any>(`
      SELECT 
        SUM(data_length + index_length) / 1024 / 1024 as total_size_mb,
        SUM(data_length) / 1024 / 1024 as data_size_mb,
        SUM(index_length) / 1024 / 1024 as index_size_mb
      FROM information_schema.tables
      WHERE table_schema = DATABASE()
    `);

    metrics.totalSizeMB = tableSize[0].total_size_mb;
    metrics.dataSizeMB = tableSize[0].data_size_mb;
    metrics.indexSizeMB = tableSize[0].index_size_mb;

    // ë©”íŠ¸ë¦­ ì €ì¥
    this.storeMetrics(metrics);

    // ì•Œë¦¼ í™•ì¸
    this.checkAlerts(metrics);

    return metrics;
  }

  // ë©”íŠ¸ë¦­ ì €ì¥
  private storeMetrics(metrics: Record<string, any>): void {
    const timestamp = Date.now();
    
    for (const [key, value] of Object.entries(metrics)) {
      if (!this.metrics.has(key)) {
        this.metrics.set(key, []);
      }
      
      const history = this.metrics.get(key)!;
      history.push({ value, timestamp });
      
      // 24ì‹œê°„ ì´ìƒ ëœ ë°ì´í„° ì œê±°
      const cutoff = timestamp - 24 * 60 * 60 * 1000;
      const filtered = history.filter(m => m.timestamp > cutoff);
      this.metrics.set(key, filtered);
    }
  }

  // ì•Œë¦¼ ì¶”ê°€
  addAlert(
    condition: (metrics: any) => boolean,
    message: string,
    severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL'
  ): void {
    this.alerts.push({ condition, message, severity });
  }

  // ì•Œë¦¼ í™•ì¸
  private checkAlerts(metrics: Record<string, any>): void {
    for (const alert of this.alerts) {
      if (alert.condition(metrics)) {
        this.sendAlert(alert.message, alert.severity);
      }
    }
  }

  // ì•Œë¦¼ ì „ì†¡
  private sendAlert(message: string, severity: string): void {
    console.log(`[${severity}] ${message}`);
    // ì‹¤ì œ êµ¬í˜„: ì´ë©”ì¼, Slack, PagerDuty ë“±
  }

  // ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
  generatePerformanceReport(): {
    summary: Record<string, any>;
    trends: Record<string, any>;
    recommendations: string[];
  } {
    const summary: Record<string, any> = {};
    const trends: Record<string, any> = {};
    const recommendations: string[] = [];

    // í˜„ì¬ ë©”íŠ¸ë¦­ ìš”ì•½
    for (const [key, history] of this.metrics.entries()) {
      if (history.length > 0) {
        const current = history[history.length - 1].value;
        const values = history.map(h => h.value);
        
        summary[key] = {
          current,
          avg: values.reduce((a, b) => a + b, 0) / values.length,
          min: Math.min(...values),
          max: Math.max(...values)
        };

        // ì¶”ì„¸ ë¶„ì„
        if (history.length > 10) {
          const recent = values.slice(-10);
          const older = values.slice(-20, -10);
          
          if (older.length > 0) {
            const recentAvg = recent.reduce((a, b) => a + b, 0) / recent.length;
            const olderAvg = older.reduce((a, b) => a + b, 0) / older.length;
            const change = ((recentAvg - olderAvg) / olderAvg) * 100;
            
            trends[key] = {
              direction: change > 0 ? 'increasing' : 'decreasing',
              changePercent: Math.abs(change)
            };
          }
        }
      }
    }

    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    if (summary.Slow_queries?.current > 10) {
      recommendations.push('Optimize slow queries or add appropriate indexes');
    }

    if (summary.Threads_connected?.current > summary.Max_used_connections?.current * 0.8) {
      recommendations.push('Consider increasing max_connections');
    }

    if (summary.totalSizeMB?.current > 10000) {
      recommendations.push('Consider archiving old data or partitioning large tables');
    }

    return { summary, trends, recommendations };
  }
}
```

### 2. ë°±ì—… ë° ë³µêµ¬

```typescript
// ë°±ì—… ê´€ë¦¬ ì‹œìŠ¤í…œ
class BackupManager {
  constructor(
    private db: DatabaseConnectionPool,
    private config: {
      backupPath: string;
      retentionDays: number;
      compression: boolean;
    }
  ) {}

  // ì „ì²´ ë°±ì—…
  async fullBackup(): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `backup_full_${timestamp}.sql`;
    const filepath = `${this.config.backupPath}/${filename}`;

    // mysqldump ì‹¤í–‰ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” child_process ì‚¬ìš©)
    const command = this.buildBackupCommand(filepath);
    
    console.log(`Starting full backup to ${filepath}`);
    // await exec(command);

    if (this.config.compression) {
      // await exec(`gzip ${filepath}`);
      return `${filepath}.gz`;
    }

    return filepath;
  }

  // ì¦ë¶„ ë°±ì—… (ë°”ì´ë„ˆë¦¬ ë¡œê·¸ ê¸°ë°˜)
  async incrementalBackup(lastPosition: string): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `backup_incr_${timestamp}.binlog`;
    const filepath = `${this.config.backupPath}/${filename}`;

    // mysqlbinlog ì‹¤í–‰
    const command = `mysqlbinlog --start-position=${lastPosition} > ${filepath}`;
    
    console.log(`Starting incremental backup from position ${lastPosition}`);
    // await exec(command);

    return filepath;
  }

  // ë°±ì—… ê²€ì¦
  async verifyBackup(backupFile: string): Promise<boolean> {
    try {
      // í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ì— ë³µì› ì‹œë„
      const testDb = 'backup_verification_test';
      
      await this.db.execute(`CREATE DATABASE IF NOT EXISTS ${testDb}`);
      
      // ë°±ì—… íŒŒì¼ ë³µì›
      const command = `mysql ${testDb} < ${backupFile}`;
      // await exec(command);

      // ê¸°ë³¸ ê²€ì¦ ì¿¼ë¦¬ ì‹¤í–‰
      await this.db.execute(`USE ${testDb}`);
      const [tables] = await this.db.execute<any>('SHOW TABLES');
      
      // ì •ë¦¬
      await this.db.execute(`DROP DATABASE ${testDb}`);

      return tables.length > 0;
    } catch (error) {
      console.error('Backup verification failed:', error);
      return false;
    }
  }

  // ë³µêµ¬ í”„ë¡œì„¸ìŠ¤
  async restore(backupFile: string, targetDb?: string): Promise<void> {
    const database = targetDb || 'restored_db';
    
    console.log(`Starting restoration to ${database}`);
    
    // ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
    await this.db.execute(`CREATE DATABASE IF NOT EXISTS ${database}`);
    
    // ë°±ì—… íŒŒì¼ ë³µì›
    const command = `mysql ${database} < ${backupFile}`;
    // await exec(command);
    
    console.log(`Restoration completed to ${database}`);
  }

  // ë°±ì—… íŒŒì¼ ê´€ë¦¬
  async cleanupOldBackups(): Promise<number> {
    const fs = require('fs').promises;
    const path = require('path');
    
    const files = await fs.readdir(this.config.backupPath);
    const now = Date.now();
    const maxAge = this.config.retentionDays * 24 * 60 * 60 * 1000;
    let deletedCount = 0;

    for (const file of files) {
      const filepath = path.join(this.config.backupPath, file);
      const stats = await fs.stat(filepath);
      
      if (now - stats.mtime.getTime() > maxAge) {
        await fs.unlink(filepath);
        deletedCount++;
        console.log(`Deleted old backup: ${file}`);
      }
    }

    return deletedCount;
  }

  private buildBackupCommand(outputFile: string): string {
    const options = [
      '--single-transaction', // InnoDB ì¼ê´€ì„±
      '--routines',           // ì €ì¥ í”„ë¡œì‹œì € í¬í•¨
      '--triggers',           // íŠ¸ë¦¬ê±° í¬í•¨
      '--events',            // ì´ë²¤íŠ¸ í¬í•¨
      '--add-drop-table',    // DROP TABLE ë¬¸ í¬í•¨
      '--create-options',    // ì „ì²´ CREATE ì˜µì…˜
      '--extended-insert',   // í™•ì¥ INSERT ë¬¸
      '--lock-tables=false', // í…Œì´ë¸” ì ê¸ˆ ë°©ì§€
      '--quick',            // ëŒ€ìš©ëŸ‰ í…Œì´ë¸” ìµœì í™”
      '--set-gtid-purged=OFF' // GTID ë¬¸ì œ ë°©ì§€
    ];

    return `mysqldump ${options.join(' ')} > ${outputFile}`;
  }
}
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### ì•ˆí‹°íŒ¨í„´ í”¼í•˜ê¸°

> [!danger] í”¼í•´ì•¼ í•  íŒ¨í„´
> - **SELECT \***: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì„ íƒ
> - **ì¸ë±ìŠ¤ ì—†ëŠ” JOIN**: JOIN ì»¬ëŸ¼ì—ëŠ” í•­ìƒ ì¸ë±ìŠ¤ í•„ìš”
> - **ê³¼ë„í•œ ì •ê·œí™”**: ì„±ëŠ¥ì„ ìœ„í•´ ì ì ˆí•œ ì—­ì •ê·œí™” ê³ ë ¤
> - **íŠ¸ëœì­ì…˜ ë‚¨ìš©**: í•„ìš”í•œ ê²½ìš°ì—ë§Œ íŠ¸ëœì­ì…˜ ì‚¬ìš©
> - **ì¤€ë¹„ë˜ì§€ ì•Šì€ ë¬¸ìì—´ ì—°ê²°**: SQL ì¸ì ì…˜ ìœ„í—˜
> - **ë¬´ì œí•œ ê²°ê³¼**: í•­ìƒ LIMIT ì‚¬ìš©
> - **ë™ê¸° ì²˜ë¦¬**: ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ë™ì‹œì„± í–¥ìƒ

### ì²´í¬ë¦¬ìŠ¤íŠ¸

| ì˜ì—­ | ì²´í¬ í•­ëª© | ì™„ë£Œ |
|------|-----------|------|
| ì„¤ê³„ | ì ì ˆí•œ ì •ê·œí™” | â˜ |
| ì„¤ê³„ | ì¸ë±ìŠ¤ ì „ëµ | â˜ |
| ì„¤ê³„ | ëª…ëª… ê·œì¹™ | â˜ |
| ê°œë°œ | Prepared Statement | â˜ |
| ê°œë°œ | ì—ëŸ¬ ì²˜ë¦¬ | â˜ |
| ê°œë°œ | íŠ¸ëœì­ì…˜ ê´€ë¦¬ | â˜ |
| ìš´ì˜ | ë°±ì—… ì „ëµ | â˜ |
| ìš´ì˜ | ëª¨ë‹ˆí„°ë§ | â˜ |
| ìš´ì˜ | ë³´ì•ˆ ì„¤ì • | â˜ |
| ìš´ì˜ | ë¬¸ì„œí™” | â˜ |

---

## ğŸ“š ì°¸ê³ ìë£Œ

### ê´€ë ¨ ë¬¸ì„œ
- [[09_normalization|ì •ê·œí™”]]
- [[08_database-index|ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤]]
- [[13_database-scaling|ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ì¼€ì¼ë§]]
- [[17_database-security|ë°ì´í„°ë² ì´ìŠ¤ ë³´ì•ˆ]]

### ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- [High Performance MySQL](https://www.oreilly.com/library/view/high-performance-mysql/9781492080503/)
- [Database Reliability Engineering](https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/)
- [SQL Performance Explained](https://sql-performance-explained.com/)

### ë„êµ¬ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬
1. **ëª¨ë‹ˆí„°ë§**: Prometheus + Grafana, DataDog, New Relic
2. **ë°±ì—…**: Percona XtraBackup, MySQL Enterprise Backup
3. **ë§ˆì´ê·¸ë ˆì´ì…˜**: Flyway, Liquibase, TypeORM Migrations
4. **ì„±ëŠ¥ ë¶„ì„**: pt-query-digest, MySQL Workbench
5. **ORM**: TypeORM, Prisma, Sequelize

---

> [!quote]
> "ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë²” ì‚¬ë¡€ëŠ” ë‹¨ìˆœí•œ ê°€ì´ë“œë¼ì¸ì´ ì•„ë‹ˆë¼, ìˆ˜ë…„ê°„ì˜ ê²½í—˜ê³¼ ì‹¤íŒ¨ì—ì„œ ì–»ì€ ì§€í˜œì…ë‹ˆë‹¤. ì´ë¥¼ ë”°ë¥´ë©´ ì•ˆì •ì ì´ê³  í™•ì¥ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."