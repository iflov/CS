---
tags:
  - database
  - scaling
  - performance
  - caching
  - optimization
created: 2025-01-08
updated: 2025-01-08
---

# ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥(Scaling)

> [!info] ê°œìš”
> ë°ì´í„°ë² ì´ìŠ¤ í™•ì¥ì€ ì¦ê°€í•˜ëŠ” ë¶€í•˜ì™€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì „ëµì…ë‹ˆë‹¤. ìˆ˜ì§ì /ìˆ˜í‰ì  í™•ì¥, ìºì‹±, ì—°ê²° í’€ë§ ë“± ë‹¤ì–‘í•œ í™•ì¥ ê¸°ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## ğŸ“‘ ëª©ì°¨

- [[#ğŸ¯ í™•ì¥ ì „ëµ]]
- [[#â¬†ï¸ ìˆ˜ì§ì  í™•ì¥]]
- [[#â¡ï¸ ìˆ˜í‰ì  í™•ì¥]]
- [[#ğŸ’¾ ìºì‹± ì „ëµ]]
- [[#ğŸ”„ Connection Pooling]]
- [[#ğŸ“Š ë¡œë“œ ë°¸ëŸ°ì‹±]]
- [[#âš¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§]]
- [[#ğŸ“š ì°¸ê³ ìë£Œ]]

---

## ğŸ¯ í™•ì¥ ì „ëµ

### í™•ì¥ì˜ í•„ìš”ì„±

> [!note] ì™œ í™•ì¥ì´ í•„ìš”í•œê°€?
> - ì‚¬ìš©ì ì¦ê°€ë¡œ ì¸í•œ ë¶€í•˜ ì¦ê°€
> - ë°ì´í„° ì–‘ì˜ ì§€ì†ì ì¸ ì¦ê°€
> - ì‘ë‹µ ì‹œê°„ ìš”êµ¬ì‚¬í•­
> - ê³ ê°€ìš©ì„± ìš”êµ¬

### í™•ì¥ ë°©ì‹ ë¹„êµ

| êµ¬ë¶„ | ìˆ˜ì§ì  í™•ì¥ (Scale-Up) | ìˆ˜í‰ì  í™•ì¥ (Scale-Out) |
|------|------------------------|-------------------------|
| **ë°©ë²•** | ì„œë²„ ì„±ëŠ¥ í–¥ìƒ | ì„œë²„ ëŒ€ìˆ˜ ì¦ê°€ |
| **ë¹„ìš©** | ì§€ìˆ˜ì  ì¦ê°€ | ì„ í˜•ì  ì¦ê°€ |
| **í•œê³„** | í•˜ë“œì›¨ì–´ í•œê³„ ì¡´ì¬ | ì´ë¡ ì  ë¬´í•œ í™•ì¥ |
| **ë³µì¡ë„** | ë‚®ìŒ | ë†’ìŒ |
| **ë‹¤ìš´íƒ€ì„** | í•„ìš” | ë¶ˆí•„ìš” |

---

## â¬†ï¸ ìˆ˜ì§ì  í™•ì¥

### í•˜ë“œì›¨ì–´ ì—…ê·¸ë ˆì´ë“œ

```typescript
// TypeScript: ì„±ëŠ¥ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
interface ServerMetrics {
  cpu: {
    usage: number;      // 0-100%
    cores: number;
    threads: number;
  };
  memory: {
    total: number;      // GB
    used: number;       // GB
    cached: number;     // GB
  };
  disk: {
    iops: number;       // I/O per second
    throughput: number; // MB/s
    latency: number;    // ms
  };
}

class PerformanceMonitor {
  private metrics: ServerMetrics[] = [];
  
  async collectMetrics(): Promise<ServerMetrics> {
    // ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
    return {
      cpu: {
        usage: Math.random() * 100,
        cores: 16,
        threads: 32
      },
      memory: {
        total: 64,
        used: 45,
        cached: 15
      },
      disk: {
        iops: 10000,
        throughput: 500,
        latency: 0.5
      }
    };
  }
  
  needsUpgrade(): boolean {
    const recent = this.metrics.slice(-100);
    const avgCpu = recent.reduce((sum, m) => sum + m.cpu.usage, 0) / recent.length;
    const avgMemory = recent.reduce((sum, m) => sum + (m.memory.used / m.memory.total), 0) / recent.length;
    
    return avgCpu > 80 || avgMemory > 0.85;
  }
}
```

### ë°ì´í„°ë² ì´ìŠ¤ íŠœë‹

```sql
-- MySQL ì„±ëŠ¥ íŠœë‹ íŒŒë¼ë¯¸í„°
-- my.cnf ì„¤ì •

[mysqld]
# ë©”ëª¨ë¦¬ ì„¤ì •
innodb_buffer_pool_size = 48G  # ì „ì²´ RAMì˜ 70-80%
innodb_buffer_pool_instances = 8
innodb_log_file_size = 2G
innodb_flush_log_at_trx_commit = 2

# ì—°ê²° ì„¤ì •
max_connections = 500
thread_cache_size = 50
table_open_cache = 4000

# ì¿¼ë¦¬ ìºì‹œ (MySQL 5.7ê¹Œì§€)
query_cache_type = 1
query_cache_size = 256M

# ì„ì‹œ í…Œì´ë¸”
tmp_table_size = 512M
max_heap_table_size = 512M
```

---

## â¡ï¸ ìˆ˜í‰ì  í™•ì¥

### Read Replica êµ¬ì„±

```typescript
// TypeScript: ì½ê¸°/ì“°ê¸° ë¶„ë¦¬ êµ¬í˜„
import { Pool, PoolConfig } from 'pg';

interface DatabaseConfig {
  master: PoolConfig;
  replicas: PoolConfig[];
}

class DatabaseCluster {
  private master: Pool;
  private replicas: Pool[] = [];
  private currentReplica = 0;
  
  constructor(config: DatabaseConfig) {
    // ë§ˆìŠ¤í„° ì—°ê²°
    this.master = new Pool(config.master);
    
    // ë ˆí”Œë¦¬ì¹´ ì—°ê²°
    config.replicas.forEach(replicaConfig => {
      this.replicas.push(new Pool(replicaConfig));
    });
  }
  
  // ì“°ê¸° ì‘ì—…
  async write(query: string, params?: any[]): Promise<any> {
    const client = await this.master.connect();
    try {
      const result = await client.query(query, params);
      return result.rows;
    } finally {
      client.release();
    }
  }
  
  // ì½ê¸° ì‘ì—… (ë¼ìš´ë“œ ë¡œë¹ˆ)
  async read(query: string, params?: any[]): Promise<any> {
    const replica = this.getNextReplica();
    const client = await replica.connect();
    try {
      const result = await client.query(query, params);
      return result.rows;
    } finally {
      client.release();
    }
  }
  
  private getNextReplica(): Pool {
    const replica = this.replicas[this.currentReplica];
    this.currentReplica = (this.currentReplica + 1) % this.replicas.length;
    return replica;
  }
  
  // ê±´ê°• ì²´í¬
  async healthCheck(): Promise<Map<string, boolean>> {
    const health = new Map<string, boolean>();
    
    // ë§ˆìŠ¤í„° ì²´í¬
    try {
      await this.master.query('SELECT 1');
      health.set('master', true);
    } catch {
      health.set('master', false);
    }
    
    // ë ˆí”Œë¦¬ì¹´ ì²´í¬
    for (let i = 0; i < this.replicas.length; i++) {
      try {
        await this.replicas[i].query('SELECT 1');
        health.set(`replica_${i}`, true);
      } catch {
        health.set(`replica_${i}`, false);
      }
    }
    
    return health;
  }
}

// ì‚¬ìš© ì˜ˆì œ
const dbCluster = new DatabaseCluster({
  master: {
    host: 'master.db.example.com',
    database: 'myapp',
    user: 'dbuser',
    password: 'password',
    max: 20
  },
  replicas: [
    {
      host: 'replica1.db.example.com',
      database: 'myapp',
      user: 'dbuser',
      password: 'password',
      max: 20
    },
    {
      host: 'replica2.db.example.com',
      database: 'myapp',
      user: 'dbuser',
      password: 'password',
      max: 20
    }
  ]
});

// ì“°ê¸° ì‘ì—…
await dbCluster.write(
  'INSERT INTO users (name, email) VALUES ($1, $2)',
  ['ê¹€ì² ìˆ˜', 'kim@example.com']
);

// ì½ê¸° ì‘ì—…
const users = await dbCluster.read('SELECT * FROM users WHERE active = true');
```

---

## ğŸ’¾ ìºì‹± ì „ëµ

### Redis ìºì‹± êµ¬í˜„

```typescript
// TypeScript: Redis ìºì‹± ë ˆì´ì–´
import Redis from 'ioredis';
import { createHash } from 'crypto';

interface CacheOptions {
  ttl?: number;  // Time to live in seconds
  prefix?: string;
}

class CacheLayer {
  private redis: Redis;
  private defaultTTL = 3600; // 1 hour
  
  constructor(redisUrl: string) {
    this.redis = new Redis(redisUrl);
  }
  
  // ìºì‹œ í‚¤ ìƒì„±
  private generateKey(query: string, params?: any[]): string {
    const hash = createHash('md5');
    hash.update(query);
    if (params) {
      hash.update(JSON.stringify(params));
    }
    return `sql:${hash.digest('hex')}`;
  }
  
  // ìºì‹œ ê°€ì ¸ì˜¤ê¸°
  async get<T>(key: string): Promise<T | null> {
    const data = await this.redis.get(key);
    if (data) {
      return JSON.parse(data);
    }
    return null;
  }
  
  // ìºì‹œ ì €ì¥
  async set(key: string, value: any, ttl?: number): Promise<void> {
    const expiry = ttl || this.defaultTTL;
    await this.redis.setex(key, expiry, JSON.stringify(value));
  }
  
  // ìºì‹œ ë¬´íš¨í™”
  async invalidate(pattern: string): Promise<void> {
    const keys = await this.redis.keys(pattern);
    if (keys.length > 0) {
      await this.redis.del(...keys);
    }
  }
  
  // Look-Aside ìºì‹± íŒ¨í„´
  async lookAside<T>(
    key: string,
    fetcher: () => Promise<T>,
    ttl?: number
  ): Promise<T> {
    // ìºì‹œ í™•ì¸
    let data = await this.get<T>(key);
    
    if (data === null) {
      // ìºì‹œ ë¯¸ìŠ¤: ë°ì´í„° ì¡°íšŒ
      data = await fetcher();
      // ìºì‹œ ì €ì¥
      await this.set(key, data, ttl);
    }
    
    return data;
  }
  
  // Write-Through ìºì‹± íŒ¨í„´
  async writeThrough<T>(
    key: string,
    value: T,
    writer: (value: T) => Promise<void>,
    ttl?: number
  ): Promise<void> {
    // ë°ì´í„°ë² ì´ìŠ¤ ì“°ê¸°
    await writer(value);
    // ìºì‹œ ì—…ë°ì´íŠ¸
    await this.set(key, value, ttl);
  }
  
  // Write-Behind ìºì‹± íŒ¨í„´ (ë¹„ë™ê¸°)
  async writeBehind<T>(
    key: string,
    value: T,
    writer: (value: T) => Promise<void>,
    ttl?: number
  ): Promise<void> {
    // ìºì‹œ ë¨¼ì € ì—…ë°ì´íŠ¸
    await this.set(key, value, ttl);
    
    // ë¹„ë™ê¸°ë¡œ ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸
    setImmediate(() => {
      writer(value).catch(err => {
        console.error('Write-behind failed:', err);
        // ì—ëŸ¬ ì²˜ë¦¬ ë¡œì§
      });
    });
  }
}

// ì‚¬ìš© ì˜ˆì œ
class UserService {
  private cache: CacheLayer;
  private db: DatabaseCluster;
  
  constructor(cache: CacheLayer, db: DatabaseCluster) {
    this.cache = cache;
    this.db = db;
  }
  
  async getUser(userId: number) {
    const key = `user:${userId}`;
    
    return this.cache.lookAside(
      key,
      async () => {
        const [user] = await this.db.read(
          'SELECT * FROM users WHERE id = $1',
          [userId]
        );
        return user;
      },
      300 // 5ë¶„ TTL
    );
  }
  
  async updateUser(userId: number, data: any) {
    const key = `user:${userId}`;
    
    await this.cache.writeThrough(
      key,
      data,
      async (userData) => {
        await this.db.write(
          'UPDATE users SET name = $1, email = $2 WHERE id = $3',
          [userData.name, userData.email, userId]
        );
      }
    );
    
    // ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”
    await this.cache.invalidate(`user:list:*`);
  }
}
```

### Memcached vs Redis

```typescript
// TypeScript: ìºì‹œ ì¶”ìƒí™”
interface CacheProvider {
  get(key: string): Promise<any>;
  set(key: string, value: any, ttl?: number): Promise<void>;
  delete(key: string): Promise<void>;
  flush(): Promise<void>;
}

class MemcachedProvider implements CacheProvider {
  // Memcached êµ¬í˜„
  async get(key: string): Promise<any> {
    // MemcachedëŠ” ë‹¨ìˆœ key-value
    return null;
  }
  
  async set(key: string, value: any, ttl?: number): Promise<void> {
    // ìµœëŒ€ 1MB ì œí•œ
  }
  
  async delete(key: string): Promise<void> {
    // ë‹¨ìˆœ ì‚­ì œ
  }
  
  async flush(): Promise<void> {
    // ì „ì²´ í”ŒëŸ¬ì‹œ
  }
}

class RedisProvider implements CacheProvider {
  // Redis êµ¬í˜„ - ë” ë§ì€ ê¸°ëŠ¥
  async get(key: string): Promise<any> {
    // RedisëŠ” ë‹¤ì–‘í•œ ë°ì´í„° êµ¬ì¡° ì§€ì›
    return null;
  }
  
  async set(key: string, value: any, ttl?: number): Promise<void> {
    // í¬ê¸° ì œí•œ ì—†ìŒ
  }
  
  async delete(key: string): Promise<void> {
    // íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ ê°€ëŠ¥
  }
  
  async flush(): Promise<void> {
    // ë°ì´í„°ë² ì´ìŠ¤ë³„ í”ŒëŸ¬ì‹œ
  }
  
  // Redis íŠ¹í™” ê¸°ëŠ¥
  async lpush(key: string, value: any): Promise<void> {}
  async zadd(key: string, score: number, value: any): Promise<void> {}
  async publish(channel: string, message: any): Promise<void> {}
}
```

---

## ğŸ”„ Connection Pooling

### ì—°ê²° í’€ êµ¬í˜„

```typescript
// TypeScript: Connection Pool êµ¬í˜„
interface PoolOptions {
  min: number;
  max: number;
  idleTimeoutMillis: number;
  connectionTimeoutMillis: number;
}

class ConnectionPool<T> {
  private connections: T[] = [];
  private availableConnections: T[] = [];
  private waitingQueue: Array<(conn: T) => void> = [];
  private options: PoolOptions;
  
  constructor(
    private createConnection: () => Promise<T>,
    private destroyConnection: (conn: T) => Promise<void>,
    options: Partial<PoolOptions> = {}
  ) {
    this.options = {
      min: options.min || 2,
      max: options.max || 10,
      idleTimeoutMillis: options.idleTimeoutMillis || 30000,
      connectionTimeoutMillis: options.connectionTimeoutMillis || 5000
    };
    
    this.initialize();
  }
  
  private async initialize() {
    // ìµœì†Œ ì—°ê²° ìˆ˜ë§Œí¼ ìƒì„±
    for (let i = 0; i < this.options.min; i++) {
      const conn = await this.createConnection();
      this.connections.push(conn);
      this.availableConnections.push(conn);
    }
  }
  
  async acquire(): Promise<T> {
    // ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ê²°ì´ ìˆìœ¼ë©´ ë°˜í™˜
    if (this.availableConnections.length > 0) {
      return this.availableConnections.pop()!;
    }
    
    // ìµœëŒ€ ì—°ê²° ìˆ˜ì— ë„ë‹¬í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    if (this.connections.length < this.options.max) {
      const conn = await this.createConnection();
      this.connections.push(conn);
      return conn;
    }
    
    // ëŒ€ê¸°
    return new Promise((resolve) => {
      const timeout = setTimeout(() => {
        const index = this.waitingQueue.indexOf(resolve);
        if (index !== -1) {
          this.waitingQueue.splice(index, 1);
          throw new Error('Connection timeout');
        }
      }, this.options.connectionTimeoutMillis);
      
      this.waitingQueue.push((conn: T) => {
        clearTimeout(timeout);
        resolve(conn);
      });
    });
  }
  
  release(connection: T): void {
    // ëŒ€ê¸° ì¤‘ì¸ ìš”ì²­ì´ ìˆìœ¼ë©´ í• ë‹¹
    if (this.waitingQueue.length > 0) {
      const waiter = this.waitingQueue.shift()!;
      waiter(connection);
    } else {
      // í’€ì— ë°˜í™˜
      this.availableConnections.push(connection);
    }
  }
  
  async destroy(): Promise<void> {
    // ëª¨ë“  ì—°ê²° ì¢…ë£Œ
    await Promise.all(
      this.connections.map(conn => this.destroyConnection(conn))
    );
    this.connections = [];
    this.availableConnections = [];
  }
  
  getPoolStats() {
    return {
      total: this.connections.length,
      available: this.availableConnections.length,
      inUse: this.connections.length - this.availableConnections.length,
      waiting: this.waitingQueue.length
    };
  }
}

// HikariCP ìŠ¤íƒ€ì¼ ì„¤ì •
class HikariStylePool {
  private config = {
    minimumIdle: 10,
    maximumPoolSize: 20,
    connectionTimeout: 30000,
    idleTimeout: 600000,
    maxLifetime: 1800000,
    leakDetectionThreshold: 60000
  };
  
  async getConnection() {
    // Leak detection
    const start = Date.now();
    const conn = await this.pool.acquire();
    
    // Proxyë¡œ ê°ì‹¸ì„œ leak detection
    return new Proxy(conn, {
      get: (target, prop) => {
        if (prop === 'close') {
          return () => {
            const duration = Date.now() - start;
            if (duration > this.config.leakDetectionThreshold) {
              console.warn(`Possible connection leak detected: ${duration}ms`);
            }
            this.pool.release(conn);
          };
        }
        return target[prop];
      }
    });
  }
}
```

---

## ğŸ“Š ë¡œë“œ ë°¸ëŸ°ì‹±

### ë°ì´í„°ë² ì´ìŠ¤ í”„ë¡ì‹œ

```typescript
// TypeScript: ProxySQL ìŠ¤íƒ€ì¼ ë¡œë“œ ë°¸ëŸ°ì„œ
interface ServerConfig {
  host: string;
  port: number;
  weight: number;
  maxConnections: number;
}

interface QueryRule {
  pattern: RegExp;
  targetGroup: 'master' | 'replica';
  cache?: boolean;
  cacheTTL?: number;
}

class DatabaseProxy {
  private servers: Map<string, ServerConfig[]> = new Map();
  private queryRules: QueryRule[] = [];
  private connections: Map<string, any[]> = new Map();
  
  constructor() {
    this.servers.set('master', []);
    this.servers.set('replica', []);
  }
  
  addServer(group: 'master' | 'replica', config: ServerConfig) {
    const servers = this.servers.get(group) || [];
    servers.push(config);
    this.servers.set(group, servers);
  }
  
  addQueryRule(rule: QueryRule) {
    this.queryRules.push(rule);
    // íŒ¨í„´ ìš°ì„ ìˆœìœ„ë¡œ ì •ë ¬
    this.queryRules.sort((a, b) => {
      if (a.pattern.source.includes('INSERT|UPDATE|DELETE')) return -1;
      if (b.pattern.source.includes('INSERT|UPDATE|DELETE')) return 1;
      return 0;
    });
  }
  
  private selectServer(group: string): ServerConfig | null {
    const servers = this.servers.get(group);
    if (!servers || servers.length === 0) return null;
    
    // Weighted round-robin
    const totalWeight = servers.reduce((sum, s) => sum + s.weight, 0);
    let random = Math.random() * totalWeight;
    
    for (const server of servers) {
      random -= server.weight;
      if (random <= 0) {
        return server;
      }
    }
    
    return servers[0];
  }
  
  async executeQuery(query: string, params?: any[]): Promise<any> {
    // ì¿¼ë¦¬ ê·œì¹™ ë§¤ì¹­
    let targetGroup: 'master' | 'replica' = 'replica';
    let shouldCache = false;
    let cacheTTL = 0;
    
    for (const rule of this.queryRules) {
      if (rule.pattern.test(query)) {
        targetGroup = rule.targetGroup;
        shouldCache = rule.cache || false;
        cacheTTL = rule.cacheTTL || 0;
        break;
      }
    }
    
    // ì„œë²„ ì„ íƒ
    const server = this.selectServer(targetGroup);
    if (!server) {
      throw new Error(`No available server in group: ${targetGroup}`);
    }
    
    // ì¿¼ë¦¬ ì‹¤í–‰
    console.log(`Routing to ${targetGroup}: ${server.host}:${server.port}`);
    
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—°ê²° í’€ì—ì„œ ì—°ê²°ì„ ê°€ì ¸ì™€ ì‹¤í–‰
    return { server, query, params };
  }
  
  // í—¬ìŠ¤ ì²´í¬
  async healthCheck(): Promise<Map<string, boolean>> {
    const health = new Map<string, boolean>();
    
    for (const [group, servers] of this.servers) {
      for (const server of servers) {
        const key = `${group}:${server.host}:${server.port}`;
        try {
          // ì‹¤ì œë¡œëŠ” SELECT 1 ì¿¼ë¦¬ ì‹¤í–‰
          health.set(key, true);
        } catch {
          health.set(key, false);
        }
      }
    }
    
    return health;
  }
}

// ì‚¬ìš© ì˜ˆì œ
const proxy = new DatabaseProxy();

// ì„œë²„ ì¶”ê°€
proxy.addServer('master', {
  host: 'master.db.example.com',
  port: 3306,
  weight: 1000,
  maxConnections: 100
});

proxy.addServer('replica', {
  host: 'replica1.db.example.com',
  port: 3306,
  weight: 900,
  maxConnections: 200
});

proxy.addServer('replica', {
  host: 'replica2.db.example.com',
  port: 3306,
  weight: 800,
  maxConnections: 200
});

// ì¿¼ë¦¬ ê·œì¹™ ì¶”ê°€
proxy.addQueryRule({
  pattern: /^(INSERT|UPDATE|DELETE)/i,
  targetGroup: 'master'
});

proxy.addQueryRule({
  pattern: /^SELECT.*FROM\s+users/i,
  targetGroup: 'replica',
  cache: true,
  cacheTTL: 300
});

// ì¿¼ë¦¬ ì‹¤í–‰
await proxy.executeQuery('SELECT * FROM users WHERE id = ?', [1]);
await proxy.executeQuery('UPDATE users SET name = ? WHERE id = ?', ['ê¹€ì² ìˆ˜', 1]);
```

---

## âš¡ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­

```typescript
// TypeScript: ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ
interface QueryMetrics {
  query: string;
  duration: number;
  rows: number;
  timestamp: Date;
}

interface PerformanceMetrics {
  qps: number;          // Queries per second
  avgLatency: number;   // ms
  p95Latency: number;   // 95 percentile
  p99Latency: number;   // 99 percentile
  errorRate: number;    // percentage
  activeConnections: number;
  slowQueries: QueryMetrics[];
}

class PerformanceMonitor {
  private queryMetrics: QueryMetrics[] = [];
  private slowQueryThreshold = 1000; // 1ì´ˆ
  
  recordQuery(query: string, duration: number, rows: number) {
    const metric: QueryMetrics = {
      query,
      duration,
      rows,
      timestamp: new Date()
    };
    
    this.queryMetrics.push(metric);
    
    // ìŠ¬ë¡œìš° ì¿¼ë¦¬ ë¡œê¹…
    if (duration > this.slowQueryThreshold) {
      console.warn(`Slow query detected: ${duration}ms`, query);
    }
    
    // ë©”ëª¨ë¦¬ ê´€ë¦¬: ìµœê·¼ 10000ê°œë§Œ ìœ ì§€
    if (this.queryMetrics.length > 10000) {
      this.queryMetrics = this.queryMetrics.slice(-10000);
    }
  }
  
  getMetrics(): PerformanceMetrics {
    const now = new Date();
    const oneMinuteAgo = new Date(now.getTime() - 60000);
    
    // ìµœê·¼ 1ë¶„ê°„ì˜ ë©”íŠ¸ë¦­
    const recentMetrics = this.queryMetrics.filter(
      m => m.timestamp > oneMinuteAgo
    );
    
    // QPS ê³„ì‚°
    const qps = recentMetrics.length / 60;
    
    // ì§€ì—° ì‹œê°„ ê³„ì‚°
    const latencies = recentMetrics.map(m => m.duration).sort((a, b) => a - b);
    const avgLatency = latencies.reduce((sum, l) => sum + l, 0) / latencies.length || 0;
    const p95Index = Math.floor(latencies.length * 0.95);
    const p99Index = Math.floor(latencies.length * 0.99);
    
    // ìŠ¬ë¡œìš° ì¿¼ë¦¬
    const slowQueries = recentMetrics
      .filter(m => m.duration > this.slowQueryThreshold)
      .sort((a, b) => b.duration - a.duration)
      .slice(0, 10);
    
    return {
      qps,
      avgLatency,
      p95Latency: latencies[p95Index] || 0,
      p99Latency: latencies[p99Index] || 0,
      errorRate: 0, // ì‹¤ì œë¡œëŠ” ì—ëŸ¬ ì¶”ì  í•„ìš”
      activeConnections: 0, // ì—°ê²° í’€ì—ì„œ ê°€ì ¸ì˜´
      slowQueries
    };
  }
  
  // Prometheus í˜•ì‹ ë©”íŠ¸ë¦­ ì¶œë ¥
  getPrometheusMetrics(): string {
    const metrics = this.getMetrics();
    
    return `
# HELP db_qps Queries per second
# TYPE db_qps gauge
db_qps ${metrics.qps}

# HELP db_latency_avg Average query latency in milliseconds
# TYPE db_latency_avg gauge
db_latency_avg ${metrics.avgLatency}

# HELP db_latency_p95 95th percentile query latency
# TYPE db_latency_p95 gauge
db_latency_p95 ${metrics.p95Latency}

# HELP db_latency_p99 99th percentile query latency
# TYPE db_latency_p99 gauge
db_latency_p99 ${metrics.p99Latency}

# HELP db_slow_queries Number of slow queries
# TYPE db_slow_queries counter
db_slow_queries ${metrics.slowQueries.length}
    `.trim();
  }
}

// EXPLAIN ë¶„ì„
class QueryAnalyzer {
  async analyzeQuery(query: string): Promise<any> {
    // EXPLAIN ì‹¤í–‰
    const explainQuery = `EXPLAIN ANALYZE ${query}`;
    
    // ê²°ê³¼ ë¶„ì„
    return {
      query,
      executionPlan: '...',
      estimatedCost: 100,
      actualTime: 50,
      rowsExamined: 1000,
      indexUsed: true,
      suggestions: [
        'Consider adding index on column X',
        'Query uses filesort, consider ORDER BY optimization'
      ]
    };
  }
}
```

---

## ğŸ“š ì°¸ê³ ìë£Œ

### ë‚´ë¶€ ë¬¸ì„œ
- [[08_database-index|ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ìŠ¤]]
- [[11_database-replication|ë°ì´í„°ë² ì´ìŠ¤ ë³µì œ]]
- [[12_partitioning-sharding|íŒŒí‹°ì…”ë‹ê³¼ ìƒ¤ë”©]]

### ì™¸ë¶€ ë¦¬ì†ŒìŠ¤
- [High Performance MySQL](https://www.oreilly.com/library/view/high-performance-mysql/9781492080503/)
- [Database Reliability Engineering](https://www.oreilly.com/library/view/database-reliability-engineering/9781491925935/)
- [ProxySQL Documentation](https://proxysql.com/documentation/)
- [Redis Documentation](https://redis.io/documentation)

### ì¶”ê°€ í•™ìŠµ ì£¼ì œ
- Query Optimization
- Database Monitoring Tools
- Auto-scaling Strategies
- Cloud Database Services
- Database Migration Strategies

---

> [!quote]
> "í™•ì¥ì„±ì€ ì²˜ìŒë¶€í„° ê³ ë ¤í•´ì•¼ í•˜ì§€ë§Œ, ê³¼ë„í•œ ìµœì í™”ëŠ” ì˜¤íˆë ¤ ë…ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¸¡ì •í•˜ê³ , ë¶„ì„í•˜ê³ , í•„ìš”í•œ ë§Œí¼ë§Œ í™•ì¥í•˜ì„¸ìš”."